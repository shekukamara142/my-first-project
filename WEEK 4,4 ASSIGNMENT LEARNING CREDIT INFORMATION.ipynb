{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solution 1 Confirmation of competition contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " learning, and what to prediction?\n",
    "\n",
    "This prompt us to learn about the Transaction Information relative to the clients and to be able to Predict the Payment Abilities of the clients. This is relative to the probability for the TARGET variable\n",
    "\n",
    "What kind of file to create and submit to Kaggle?\n",
    "For each SK_ID_CURR in the test set, you must be able to predict a probability for the TARGET variable.\n",
    "\n",
    "NOTE: The file should contain a header and have the following format: SK_ID_CURR,TARGET\n",
    "\n",
    "100001,0.1\n",
    "100005,0.9\n",
    "100013,0.2 etc.\n",
    "\n",
    " Index value will be used to evaluate the submissions?\n",
    " \n",
    "The submissions are evaluated on area under the Receiver Operating Characteristic(ROC) curve between the predicted probability and the observed target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solution 2 Learning and verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all needed libraries\n",
    "\n",
    "Loading the data (Application_train_csv)\n",
    "\n",
    "Delete the Null data (empty data)\n",
    "\n",
    "Extract or separate them into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('application_train.csv')\n",
    "\n",
    "\n",
    "cleaned_df = df.dropna()\n",
    "\n",
    "\n",
    "X = cleaned_df.loc[:,[\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"AMT_ANNUITY\"]]\n",
    "y = cleaned_df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()#loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.052153197403226256\n",
      "ROC 0.5938285747369815\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_trans = scaler.transform(X_train)\n",
    "X_test_trans = scaler.transform(X_test)\n",
    "\n",
    "reg = LinearRegression().fit(X_train_trans, y_train)\n",
    "\n",
    "reg_pred = reg.predict(X_test_trans)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_true=y_test, y_pred=reg_pred))\n",
    "print(\"ROC\", roc_auc_score(y_test,reg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "solution 3 Estimation on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Estimation on the test data (application_test.csv ) and submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('application_test.csv')\n",
    "\n",
    "test_cleaned_df = test_df.dropna(axis=0)\n",
    "\n",
    "test_X = test_cleaned_df.loc[:,[\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"AMT_ANNUITY\"]]\n",
    "\n",
    "test_scaler = StandardScaler()\n",
    "test_X_test_trans = scaler.fit_transform(test_X)\n",
    "\n",
    "test_reg_pred = reg.predict(test_X_test_trans)\n",
    "#submitting to kaggle\n",
    "kgl_submission = pd.concat([test_df['SK_ID_CURR'], pd.Series(test_reg_pred, name='TARGET')], axis=1)\n",
    "kgl_submission = kgl_submission.fillna(0)\n",
    "kgl_submission.at[648,'TARGET']= 0\n",
    "kgl_submission.shape\n",
    "kgl_submission.to_csv('kggl_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "solution 4 Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " improving accuracy, perform Feature Engineering from the following perspectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature to use?\n",
    "How to preprocess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 1 of training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "imp_mean = SimpleImputer(strategy='mean')\n",
    "\n",
    "# deleting the missing values\n",
    "imp_X = imp_mean.fit_transform(X)\n",
    "\n",
    "# One hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_imp_X = enc.fit_transform(imp_X).toarray()\n",
    "\n",
    "# splitting the data into training and testing data using train_test_split from sklearn\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(enc_imp_X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# we standardized the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_1)\n",
    "X_train_trans_1 = scaler.transform(X_train_1)\n",
    "X_test_trans_1 = scaler.transform(X_test_1)\n",
    "\n",
    "# fitting the data\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(random_state=5)\n",
    "lgb = lgbm.fit(X_train_trans_1, y_train_1)\n",
    "\n",
    "# predicting\n",
    "reg_pred_1 = lgb.predict(X_test_trans_1)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test_1,reg_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern 2 of training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_median = SimpleImputer(strategy='median')\n",
    "\n",
    "# deleting the missing values\n",
    "imp_X_1 = imp_median.fit_transform(X)\n",
    "\n",
    "# One hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc_1 = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_imp_X_1 = enc.fit_transform(imp_X_1).toarray()\n",
    "\n",
    "# splitting the data into training and testing data using train_test_split from sklearn\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(enc_imp_X_1, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# we standardized the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_2)\n",
    "X_train_trans_2 = scaler.transform(X_train_2)\n",
    "X_test_trans_2 = scaler.transform(X_test_2)\n",
    "\n",
    "# fitting the data\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_1 = LGBMClassifier(random_state=5)\n",
    "lgb_1 = lgbm_1.fit(X_train_trans_2, y_train_2)\n",
    "\n",
    "# predicting\n",
    "reg_pred_2 = lgb_1.predict(X_test_trans_2)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test_2,reg_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pattern 3 of training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imp_mf = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# deleting the missing values\n",
    "imp_X_2 = imp_mf.fit_transform(X)\n",
    "\n",
    "# One hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc_2 = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_imp_X_2 = enc.fit_transform(imp_X_2).toarray()\n",
    "\n",
    "# splitting the data into training and testing data using train_test_split from sklearn\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(enc_imp_X_2, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# we standardized the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_3)\n",
    "X_train_trans_3 = scaler.transform(X_train_3)\n",
    "X_test_trans_3 = scaler.transform(X_test_3)\n",
    "\n",
    "# fitting the data\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_2 = LGBMClassifier(random_state=5)\n",
    "lgb_2 = lgbm_2.fit(X_train_trans_3, y_train_3)\n",
    "\n",
    "# predicting\n",
    "reg_pred_3 = lgb_2.predict(X_test_trans_3)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test_3,reg_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pattern 4 of training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cnst = SimpleImputer(strategy='constant')\n",
    "\n",
    "# deleting the missing values\n",
    "imp_X_3 = imp_cnst.fit_transform(X)\n",
    "\n",
    "# One hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc_3 = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_imp_X_3 = enc.fit_transform(imp_X_3).toarray()\n",
    "\n",
    "# splitting the data into training and testing data using train_test_split from sklearn\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(enc_imp_X_3, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# we standardized the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_4)\n",
    "X_train_trans_4 = scaler.transform(X_train_4)\n",
    "X_test_trans_4 = scaler.transform(X_test_4)\n",
    "\n",
    "# fitting the data\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_3 = LGBMClassifier(random_state=5)\n",
    "lgb_3 = lgbm_3.fit(X_train_trans_4, y_train_4)\n",
    "\n",
    "# predicting\n",
    "reg_pred_4 = lgb_3.predict(X_test_trans_4)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test_4,reg_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pattern 5 of training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cnst = SimpleImputer(strategy='constant')\n",
    "\n",
    "# deleting the missing values\n",
    "imp_X_4 = imp_cnst.fit_transform(X)\n",
    "\n",
    "# One hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc_4 = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_imp_X_4 = enc.fit_transform(imp_X_4).toarray()\n",
    "\n",
    "# splitting the data into training and testing data using train_test_split from sklearn\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(enc_imp_X_4, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# we standardizied data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_5)\n",
    "X_train_trans_5 = scaler.transform(X_train_5)\n",
    "X_test_trans_5 = scaler.transform(X_test_5)\n",
    "\n",
    "# fitting the data\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_4 = LGBMClassifier(random_state=5)\n",
    "lgb_4 = lgbm_4.fit(X_train_trans_5, y_train_5)\n",
    "\n",
    "# predicting\n",
    "reg_pred_5 = lgb_4.predict(X_test_trans_5)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test_5,reg_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
